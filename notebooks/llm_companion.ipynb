{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8868aa86",
   "metadata": {},
   "source": [
    "# LLM Concepts: Companion Notebook\n",
    "\n",
    "This notebook lets you explore key LLM concepts hands-on using Amazon Bedrock and Anthropic Claude models.\n",
    "\n",
    "**Note:** You must have access to AWS Bedrock and appropriate permissions to use Claude models. **Do not share your AWS credentials.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6adf0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- AWS Setup ---\n",
    "# Fill in your AWS credentials and region below.\n",
    "import os\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError, ClientError\n",
    "\n",
    "# Option 1: Use environment variables (recommended\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'YOUR_ACCESS_KEY'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'YOUR_SECRET_KEY'\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'us-east-1'  # or your region\n",
    "\n",
    "\n",
    "region = os.environ.get('AWS_DEFAULT_REGION', 'us-east-1')\n",
    "\n",
    "# Check Bedrock access\n",
    "bedrock = boto3.client('bedrock-runtime', region_name=region)\n",
    "bedrock_available = True\n",
    "try:\n",
    "    # Try listing available models\n",
    "    resp = bedrock.list_foundation_models()\n",
    "    claude_models = [m for m in resp.get('modelSummaries', []) if 'anthropic' in m['modelId'].lower()]\n",
    "    if not claude_models:\n",
    "        print('Claude models not found in your Bedrock account.')\n",
    "        bedrock_available = False\n",
    "except (NoCredentialsError, ClientError) as e:\n",
    "    print('Bedrock/Claude not available or credentials missing:', e)\n",
    "    bedrock_available = False\n",
    "\n",
    "if not bedrock_available:\n",
    "    print('Some cells will be skipped. Please check your AWS setup.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4182ae7e",
   "metadata": {},
   "source": [
    "## 1. Introduction to LLMs (Claude via Bedrock)\n",
    "A Large Language Model (LLM) is an AI system trained on vast text data to generate and understand human language. Let's try a simple prompt with Claude!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf0fd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "if bedrock_available:\n",
    "    prompt = 'Explain what a Large Language Model is in one sentence.'\n",
    "    model_id = claude_models[0]['modelId'] if claude_models else 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "    response = bedrock.invoke_model(\n",
    "        modelId=model_id,\n",
    "        body='{\"prompt\": \"' + prompt + '\", \"max_tokens_to_sample\": 100}',\n",
    "        contentType='application/json'\n",
    "    )\n",
    "    import json\n",
    "    result = json.loads(response['body'].read())\n",
    "    print('Claude:', result.get('completion', result))\n",
    "else:\n",
    "    print('Bedrock/Claude not available. Skipping this cell.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326dd70c",
   "metadata": {},
   "source": [
    "## 2. Tokenization Demo\n",
    "Tokenization splits text into tokens for the model. Let's see how Claude tokenizes a sample sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e96b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = 'Machine learning is fascinating!'\n",
    "if bedrock_available:\n",
    "    # Claude does not expose a tokenizer API directly, but you can estimate tokens by sending a prompt and checking usage\n",
    "    prompt = f'Count the number of tokens in: {sample_text!r} and list the tokens.'\n",
    "    response = bedrock.invoke_model(\n",
    "        modelId=model_id,\n",
    "        body='{\"prompt\": \"' + prompt + '\", \"max_tokens_to_sample\": 100}',\n",
    "        contentType='application/json'\n",
    "    )\n",
    "    import json\n",
    "    result = json.loads(response['body'].read())\n",
    "    print(result.get('completion', result))\n",
    "else:\n",
    "    print('Bedrock/Claude not available. Skipping this cell.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d6645f",
   "metadata": {},
   "source": [
    "## 3. Embeddings Visualization\n",
    "Embeddings are vector representations of text. Let's get embeddings for a few sentences and visualize them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e50f9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "sentences = [\n",
    "    'I love machine learning.',\n",
    "    'Artificial intelligence is the future.',\n",
    "    'The cat sat on the mat.',\n",
    "    'Dogs are loyal pets.'\n",
    "]\n",
    "if bedrock_available:\n",
    "    # Claude's embedding API is not public as of now; this is a placeholder for when it becomes available\n",
    "    print('Claude embedding API not available. Skipping this cell.')\n",
    "else:\n",
    "    print('Bedrock/Claude not available. Skipping this cell.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c271968c",
   "metadata": {},
   "source": [
    "## 4. Softmax, Temperature, topP, topK Demo\n",
    "Let's see how softmax and sampling parameters affect token selection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f94254f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msoftmax\u001b[39m(logits, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def softmax(logits, temperature=1.0):\n",
    "    scaled = np.array(logits) / temperature\n",
    "    exps = np.exp(scaled - np.max(scaled))\n",
    "    return exps / np.sum(exps)\n",
    "\n",
    "logits = [8.2, 4.6, 3.9, 3.2, -5.0]\n",
    "tokens = ['Paris', 'Lyon', 'Nice', 'Marseille', 'banana']\n",
    "\n",
    "def plot_probs(temperature):\n",
    "    probs = softmax(logits, temperature)\n",
    "    plt.figure(figsize=(7,3))\n",
    "    plt.bar(tokens, probs, color='#3498db')\n",
    "    plt.title(f'Softmax Probabilities (Temperature={temperature})')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.ylim(0,1)\n",
    "    plt.show()\n",
    "\n",
    "plot_probs(1.0)\n",
    "# Try plot_probs(0.5) or plot_probs(1.5) to see the effect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b11894",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Requirements:**\n",
    "- boto3\n",
    "- matplotlib\n",
    "- scikit-learn (for PCA, if embeddings become available)\n",
    "\n",
    "You can install them with:\n",
    "```python\n",
    "!pip install boto3 matplotlib scikit-learn\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
